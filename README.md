# Kaggle Competition

# 项目简介
本项目基于 Kaggle 平台的一项数据建模比赛，目标是利用多维特征变量预测一个连续型目标变量 `y`，属于典型的回归任务。项目完整实现了从数据预处理、特征工程、模型选择、参数调优到模型评估的数据挖掘全流程。

数据来源为 Kaggle 提供的比赛数据。

# 文件说明
RF.py使用 Random Forest 回归模型进行交叉验证，输出每组参数的验证集 RMSE，并输出最佳参数组合。 
RF plot.py使用最佳参数训练 Random Forest 模型，并绘制验证集真实值 vs 预测值散点图，保存为 `rf_validation_plot.png`。 
catboost selection.py先用 Random Forest 的特征重要性筛选累计贡献率 ≤ 95% 的特征，再对 CatBoost 模型进行多组超参数组合的验证，输出最佳参数与 RMSE。 
trainingdata.csv训练数据文件，包含目标列 `y` 与多维特征列。 

# 数据探索与预处理
1. 数据分布分析
   - 检查特征分布、缺失值比例以及变量间相关性  
   - 发现部分变量存在长尾分布或偏态分布或近似常数  

2. 数据变换    
   - 剔除近似常数或高频单值的冗余特征，降低噪声

3. 特征冗余处理  
   - 通过方差过滤和唯一值比例判断，移除信息贡献极低的特征

---

# 特征工程与特征选择
- 使用随机森林特征重要性指标进行筛选  
- 按累计贡献率保留信息量最高的特征，并测试不同阈值（90%、95%、97%、99%）  
- 95%累计重要性方案在多模型下表现稳定，最终被采纳为主方案

---

# 模型选择与调优
1. Random Forest  
   - 调参范围：`n_estimators`, `max_depth`, `max_features`  
   - 使用 5-Fold 交叉验证  
   - 比较默认配置与调优结果，发现特征选择策略显著提升了泛化能力（10%-20%）

2. CatBoost  
   - 利用其类别特征处理能力与内置正则化机制  
   - 初始配置（未调参）在验证集上取得 RMSE ≈ 0.434  
   - 结合 95% 累计重要性特征并调整 `depth`, `learning_rate` 后，RMSE 降至0.42749，为最佳方案

---

# 最终结果
| 模型            | 特征选择阈值 | 验证集 RMSE |
|----------------|-------------|-------------|
| Random Forest  | 95%         | 0.49-0.50   |
| CatBoost       | 95%         | 0.42749     |

---

# 项目收获
- 掌握了从数据探索到建模的全流程实现
- 熟悉了基于特征重要性的筛选方法
- 提升了对模型解释性、调参策略与模型选择的理解
- 熟悉了Random Forest与CatBoost在结构化数据预测中的应用

---
# 验证集真实值 vs 预测值散点图
<img width="600" height="600" alt="image" src="https://github.com/user-attachments/assets/b69d5445-6318-43fd-bf13-e95cadb1923f" />

